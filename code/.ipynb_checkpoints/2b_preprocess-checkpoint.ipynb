{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; import os; from analysis_helpers import *; import warnings\n",
    "from analysis_helpers import *\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "from scipy.interpolate import pchip\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import argrelextrema\n",
    "import pingouin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'behav_b.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8e98781cf160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'behav_b.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'behav_b.csv'"
     ]
    }
   ],
   "source": [
    "b = pd.read_csv('behav_b.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b[b['Trial Type'].isin(['Presentation','Memory'])]\n",
    "b = b[['Unnamed: 0', 'Attention Button', 'Attention Level', 'Attention Probe',\n",
    "       'Attention Reaction Time (s)', 'Attention Reaction Time (s).1',\n",
    "       'Category', 'Cue Validity', 'Cued Category', 'Cued Composite',\n",
    "       'Cued Face', 'Cued Place', 'Cued Side', 'Experiment',\n",
    "       'Familiarity Rating', 'Familiarity Reaction Time (s)', #'Group',\n",
    "       'Memory Image', 'Post Invalid Cue', 'Pre Invalid Cue', 'Rating History',\n",
    "       'Run', 'Stimulus End', 'Stimulus Onset', 'Subject', 'Trial',\n",
    "       'Trial Type', 'Uncued Composite', 'Uncued Face', 'Uncued Place',\n",
    "       'UniqueID', 'Unnamed: 0.1', 'Unnamed: 0.1.1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add last-cued category to memory trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,x in b[(b['Trial']==9)&(b['Trial Type']=='Presentation')].iterrows():\n",
    "    b.loc[(b['UniqueID']==x['UniqueID']) &\n",
    "         (b['Run']==x['Run'])\n",
    "         &(b['Trial Type']=='Memory'),'Cued Category'] = x['Cued Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.loc[(b['Attention Level']=='Novel') & (b['Cued Category']=='Face' ) & (b['Category']=='Face' ), 'Attention Level'] = 'Novel_Cued_Cat'\n",
    "b.loc[(b['Attention Level']=='Novel') & (b['Cued Category']=='Place') & (b['Category']=='Place'), 'Attention Level'] = 'Novel_Cued_Cat'\n",
    "b.loc[(b['Attention Level']=='Novel') & (b['Cued Category']=='Face' ) & (b['Category']=='Place'), 'Attention Level'] = 'Novel_Uncued_Cat'\n",
    "b.loc[(b['Attention Level']=='Novel') & (b['Cued Category']=='Place') & (b['Category']=='Face' ), 'Attention Level'] = 'Novel_Uncued_Cat'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save behavioral data with added info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.to_csv('behavioral.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['Attention Level'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load gaze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.read_csv('mem_gaze_b.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mean pupil size (both eyes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pupil pupil data and add mean pupil size to mem gaze dataframe\n",
    "for eye in ['righteye','lefteye']:\n",
    "    m[eye] = m[eye].str.split(', ',expand=True)[4]  \n",
    "    m[eye] = m[eye].str.split(': ',expand=True)[1]\n",
    "    m[eye] = m[eye].astype(float)\n",
    "\n",
    "m = m[(m['righteye']>0) & (m['lefteye']>0)]\n",
    "\n",
    "m['Pupil_mean'] = (m['righteye'] + m['lefteye']) / 2\n",
    "m['pupil_mean'] = (m['righteye'] + m['lefteye']) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add behavioral info to gaze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# now that we have only good mem trials in the behavioral df\n",
    "# we want to also subselect just those mem trials in the gaze data\n",
    "\n",
    "# make empty list\n",
    "mem_gaze_rest = []\n",
    "m['Attention Level'],m['Familiarity Rating'],m['Familiarity Reaction Time (s)'],m['good_gaze'], m['Cued Category']=np.nan,np.nan,np.nan,np.nan,np.nan\n",
    "\n",
    "# now we can loop over each subject\n",
    "for u in b['UniqueID'].unique():\n",
    "    \n",
    "    print(' '); print(u); print('------------')\n",
    "    \n",
    "    # select the data for that subject\n",
    "    f = b[(b['UniqueID']==u)&(b['Trial Type']=='Memory')]\n",
    "    \n",
    "    # loop over each run\n",
    "    for r in f['Run'].unique():\n",
    "        print(r)\n",
    "        \n",
    "        # loop over each trial\n",
    "        for t in f[(f['Run']==r)]['Trial'].unique():\n",
    "            \n",
    "            #if f[(f['Run']==r) & (f['Trial']==t)]['Attention Level'].str.contains('Novel').item():\n",
    "            \n",
    "            # add behavioral info to 'good gaze' trials in memory gaze dict and label them as 'good gaze'\n",
    "            m.loc[(m['UniqueID']==u)&(m['Run']==r)&(m['Trial']==t), 'Attention Level'] = b[(b['UniqueID']==u)&(b['Trial Type']=='Memory')&(b['Run']==r)&(b['Trial']==t)]['Attention Level'].item()\n",
    "            m.loc[(m['UniqueID']==u)&(m['Run']==r)&(m['Trial']==t), 'Familiarity Rating'] = b[(b['UniqueID']==u)&(b['Trial Type']=='Memory')&(b['Run']==r)&(b['Trial']==t)]['Familiarity Rating'].item()\n",
    "            m.loc[(m['UniqueID']==u)&(m['Run']==r)&(m['Trial']==t), 'Familiarity Reaction Time (s)'] = b[(b['UniqueID']==u)&(b['Trial Type']=='Memory')&(b['Run']==r)&(b['Trial']==t)]['Familiarity Reaction Time (s)'].item()\n",
    "            m.loc[(m['UniqueID']==u)&(m['Run']==r)&(m['Trial']==t), 'Category'] = b[(b['UniqueID']==u)&(b['Trial Type']=='Memory')&(b['Run']==r)&(b['Trial']==t)]['Category'].item()\n",
    "            m.loc[(m['UniqueID']==u)&(m['Run']==r)&(m['Trial']==t), 'good_gaze'] = 1\n",
    "            m.loc[(m['UniqueID']==u)&(m['Run']==r)&(m['Trial']==t), 'Cued Category'] = b[(b['UniqueID']==u)&(b['Trial Type']=='Presentation')&(b['Run']==r)&(b['Trial']==9)]['Cued Category'].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.to_csv('m_w_behavioral.csv')\n",
    "# m = pd.read_csv('m_w_behavioral.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate cases where Mean Pupil size is zero and Familiarity Reaction Time is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = m[(m['pupil_mean']>0) & (m['Familiarity Reaction Time (s)']>0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate cases where gaze location is off the screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg['x_righteye'] = (59.8/2048)*mg['xRaw_righteye']\n",
    "mg['x_lefteye']  = (59.8/2048)*mg['xRaw_lefteye']\n",
    "mg['y_righteye'] = (33.6/1152)*mg['yRaw_righteye']\n",
    "mg['y_lefteye']  = (33.6/1152)*mg['yRaw_lefteye']\n",
    "\n",
    "mg = mg[(mg['x_righteye']>=0)  & (mg['x_righteye']<=59.8) \n",
    "        & (mg['x_lefteye']>=0) & (mg['x_lefteye']<=59.8) \n",
    "        & (mg['y_righteye']<=33.6)  & (mg['y_righteye']>=0)\n",
    "        & (mg['y_lefteye']  <=33.6) & (mg['y_lefteye']>=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate pupil differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg['pupil_diff'] = abs(mg['righteye'] - mg['lefteye'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate pupil-difference outliers (IQR based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "\n",
    "# Computing IQR\n",
    "Q1  = mg['pupil_diff'].quantile(0.25)\n",
    "Q3  = mg['pupil_diff'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "upper = Q3 + 1.5 * IQR\n",
    "lower = Q1 - 1.5 * IQR\n",
    "\n",
    "mg['IQR_Outlier'] = np.nan\n",
    "mg.loc[(mg['pupil_diff']<upper) & (mg['pupil_diff']>lower),'IQR_Outlier'] = 0\n",
    "mg.loc[(mg['pupil_diff']>upper) | (mg['pupil_diff']<lower),'IQR_Outlier'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set mg equal to mg without outliers\n",
    "mg = mg[(mg['IQR_Outlier']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sb.violinplot(x='pupil_diff', data=mg[mg['IQR_Outlier']==0])\n",
    "sb.boxplot(x='pupil_diff', data=mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate gaze location outliers (IQR based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing IQR - x coord ######\n",
    "Q1  = mg['av_x_coord'].quantile(0.25)\n",
    "Q3  = mg['av_x_coord'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "x_upper = Q3 + 1.5 * IQR\n",
    "x_lower = Q1 - 1.5 * IQR\n",
    "\n",
    "#mg_new = mg[(mg['av_x_coord'] > lower)&(mg['av_x_coord'] < upper)]\n",
    "\n",
    "\n",
    "# Computing IQR - y coord ######\n",
    "Q1  = mg['av_y_coord'].quantile(0.25)\n",
    "Q3  = mg['av_y_coord'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "y_upper = Q3 + 1.5 * IQR\n",
    "y_lower = Q1 - 1.5 * IQR\n",
    "\n",
    "mg_new = mg[(mg['av_y_coord'] > y_lower)&(mg['av_y_coord'] < y_upper)&\n",
    "               (mg['av_x_coord'] > x_lower)&(mg['av_x_coord'] < x_upper)]\n",
    "\n",
    "mg_ex = mg[~(mg['av_y_coord'] > y_lower)|~(mg['av_y_coord'] < y_upper)\n",
    "               & ~(mg['av_x_coord'] > x_lower)&~(mg['av_x_coord'] < x_upper)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_new.to_csv('mg_new_mem.csv')\n",
    "# mg_new = pd.read_csv('mg_new_mem.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = mg_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg['zscore'] = np.nan \n",
    "\n",
    "for s in mg['UniqueID'].unique():\n",
    "    \n",
    "    subject = mg[(mg['UniqueID']==s) ]\n",
    "    mg.loc[(mg['UniqueID']==s) , 'zscore'] = (subject.pupil_mean - subject.pupil_mean.mean())/subject.pupil_mean.std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.loc[(b['Attention Level']=='Novel') & (b['Cued Category']=='Face' ) & (b['Category']=='Face' ), 'Attention Level'] = 'Novel_Cued_Cat'\n",
    "b.loc[(b['Attention Level']=='Novel') & (b['Cued Category']=='Place') & (b['Category']=='Place'), 'Attention Level'] = 'Novel_Cued_Cat'\n",
    "b.loc[(b['Attention Level']=='Novel') & (b['Cued Category']=='Face' ) & (b['Category']=='Place'), 'Attention Level'] = 'Novel_Uncued_Cat'\n",
    "b.loc[(b['Attention Level']=='Novel') & (b['Cued Category']=='Place') & (b['Category']=='Face' ), 'Attention Level'] = 'Novel_Uncued_Cat'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.loc[(mg['Attention Level']=='Novel') & (mg['Cued Category']=='Face' ) & (mg['Category']=='Face' ), 'Attention Level'] = 'Novel_Cued_Cat'\n",
    "mg.loc[(mg['Attention Level']=='Novel') & (mg['Cued Category']=='Place') & (mg['Category']=='Place'), 'Attention Level'] = 'Novel_Cued_Cat'\n",
    "mg.loc[(mg['Attention Level']=='Novel') & (mg['Cued Category']=='Face' ) & (mg['Category']=='Place'), 'Attention Level'] = 'Novel_Uncued_Cat'\n",
    "mg.loc[(mg['Attention Level']=='Novel') & (mg['Cued Category']=='Place') & (mg['Category']=='Face' ), 'Attention Level'] = 'Novel_Uncued_Cat' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add time_from_onset and time_pre_response to gaze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg['timestamp'] = mg.timestamp.astype(float)\n",
    "mg['time_from_onset'] = np.nan\n",
    "mg['time_pre_response'] = np.nan\n",
    "\n",
    "for s in mg['UniqueID'].unique():\n",
    "    print(s)\n",
    "    \n",
    "    data = mg[mg['UniqueID']==s]\n",
    "    \n",
    "    for r in data['Run'].unique():\n",
    "        for t in data[(data['Run']==r)]['Trial'].unique():\n",
    "            \n",
    "            this_trial = data[(data['Run']==r) & (data['Trial']==t)]\n",
    "            mg.loc[(mg['Run']==r) & (mg['Trial']==t) &(mg['UniqueID']==s),'time_from_onset']=this_trial['timestamp']-this_trial.iloc[0]['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg['time_pre_response'] = mg['Familiarity Reaction Time (s)'] - mg['time_from_onset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.to_csv('mg_new_MEM_w_onset_times.csv')\n",
    "# mg = pd.read_csv('mg_w_onset_times.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate each trial's average gazepoints per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg['gaze_resolution'] = np.nan\n",
    "mg['max_time'] = np.nan\n",
    "\n",
    "\n",
    "for s in mg['UniqueID'].unique():\n",
    "    \n",
    "    print(s)\n",
    "    \n",
    "    for r in mg[(mg['UniqueID']==s)]['Run'].unique():\n",
    "        for t in mg[(mg['UniqueID']==s) & (mg['Run']==r)]['Trial'].unique():\n",
    "            \n",
    "            dat = mg[(mg['UniqueID']==s) & (mg['Run']==r) &(mg['Trial']==t)]\n",
    "            dat = dat.drop_duplicates('time_from_onset')\n",
    "            \n",
    "            mg.loc[(mg['UniqueID']==s) & (mg['Run']==r) &(mg['Trial']==t), 'max_time'] = dat['time_from_onset'].max()\n",
    "            \n",
    "            if mg[(mg['UniqueID']==s) & (mg['Run']==r) &(mg['Trial']==t)]['time_from_onset'].max()-mg[(mg['UniqueID']==s) & (mg['Run']==r) &(mg['Trial']==t)]['time_from_onset'].min() != 0:\n",
    "                mg.loc[(mg['UniqueID']==s) & (mg['Run']==r) &(mg['Trial']==t),'gaze_resolution']=dat.shape[0]/3\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.to_csv('mg_MEM_new_with_resolution.csv')\n",
    "# mg = pd.read_csv('mg_with_resolution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg['Attention Level'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select trials with an average 20 or more gazepoints per second "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_res = mg[(mg['gaze_resolution']>=20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate gaze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terpy = []; attention = []; familiarity = []; run = []; trial = []; sub = []\n",
    "timepoints = []; category = []; cued_category = []\n",
    "\n",
    "for s in mg_res['UniqueID'].unique():\n",
    "    print(s)\n",
    "    for r in mg_res[(mg_res['UniqueID']==s)]['Run'].unique():\n",
    "        for t in mg_res[(mg_res['UniqueID']==s) & (mg_res['Run']==r)]['Trial'].unique():\n",
    "            \n",
    "            dat = mg_res[(mg_res['UniqueID']==s) & (mg_res['Run']==r) & (mg_res['Trial']==t)]\n",
    "            dat = dat.drop_duplicates('time_from_onset')\n",
    "            \n",
    "            x = dat['time_from_onset']\n",
    "            y = dat['zscore']\n",
    "            y_val = dat['Pupil_mean']\n",
    "            \n",
    "            upper_dat = x.max()\n",
    "            l = list(np.linspace(0,3,150))\n",
    "            minnie = min(l, key=lambda x:abs(x-upper_dat))\n",
    "            i = l.index(minnie)\n",
    "            xx = l[0:i+1]\n",
    "            \n",
    "            if x.shape[0] >= 2:\n",
    "            \n",
    "                interp = pchip(x, y)\n",
    "                yy = interp(xx)\n",
    "                \n",
    "                terpy.extend(yy)\n",
    "                timepoints.extend(xx)\n",
    "            \n",
    "                attention.extend(list(dat['Attention Level'].unique())*len(xx))\n",
    "                category.extend(list(dat['Category'].unique())*len(xx))\n",
    "                cued_category.extend(list(dat['Cued Category'].unique())*len(xx))\n",
    "                familiarity.extend(list(dat['Familiarity Rating'].unique())*len(xx))\n",
    "                run.extend(list(dat['Run'].unique())*len(xx))\n",
    "                trial.extend(list(dat['Trial'].unique())*len(xx))\n",
    "                sub.extend(list(dat['UniqueID'].unique())*len(xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'Time':timepoints, 'UniqueID':sub, 'Run':run, 'Category': category, 'Cued Category': cued_category, 'Trial':trial,'Interp':terpy, 'Attention Level':attention, 'Familiarity Rating': familiarity}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_nov = pd.DataFrame(data_dict)\n",
    "d_nov['Experiment'] = np.nan\n",
    "d_nov.loc[d_nov['UniqueID']<30, 'Experiment']  = 'Sustained'\n",
    "d_nov.loc[d_nov['UniqueID']>=30, 'Experiment'] = 'Variable'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_nov.to_csv('d_nov_MEM_mg_new_b.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
