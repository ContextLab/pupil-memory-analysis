{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; import os; from analysis_helpers import *; import warnings\n",
    "from analysis_helpers import *\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "from scipy.interpolate import pchip\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import argrelextrema\n",
    "import pingouin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "b     = pd.read_csv('behavioral.csv') \n",
    "d_nov = pd.read_csv('d_nov_pres.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add last-cued category to memory trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx,x in b[(b['Trial']==9)&(b['Trial Type']=='Presentation')].iterrows():\n",
    "#     b.loc[(b['UniqueID']==x['UniqueID']) &\n",
    "#          (b['Run']==x['Run'])\n",
    "#          &(b['Trial Type']=='Memory'),'Cued Category'] = x['Cued Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b.loc[(b['Attention Level']=='Novel') & (b['Cued Category']=='Face' ) & (b['Category']=='Face' ), 'Attention Level'] = 'Novel_Cued_Cat'\n",
    "# b.loc[(b['Attention Level']=='Novel') & (b['Cued Category']=='Place') & (b['Category']=='Place'), 'Attention Level'] = 'Novel_Cued_Cat'\n",
    "# b.loc[(b['Attention Level']=='Novel') & (b['Cued Category']=='Face' ) & (b['Category']=='Place'), 'Attention Level'] = 'Novel_Uncued_Cat'\n",
    "# b.loc[(b['Attention Level']=='Novel') & (b['Cued Category']=='Place') & (b['Category']=='Face' ), 'Attention Level'] = 'Novel_Uncued_Cat'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate behavioral and variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bvar = b[(b['UniqueID']>=30)] \n",
    "bsus = b[(b['UniqueID']<=29)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All images, Variable --> significant effect of Category, Attention Level, and interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>SS</th>\n",
       "      <th>ddof1</th>\n",
       "      <th>ddof2</th>\n",
       "      <th>MS</th>\n",
       "      <th>F</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>p-GG-corr</th>\n",
       "      <th>np2</th>\n",
       "      <th>eps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Category</td>\n",
       "      <td>3.457534</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3.457534</td>\n",
       "      <td>10.892946</td>\n",
       "      <td>3.258622e-03</td>\n",
       "      <td>3.258622e-03</td>\n",
       "      <td>0.331164</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attention Level</td>\n",
       "      <td>13.437214</td>\n",
       "      <td>5</td>\n",
       "      <td>110</td>\n",
       "      <td>2.687443</td>\n",
       "      <td>27.729559</td>\n",
       "      <td>4.463426e-18</td>\n",
       "      <td>8.250565e-09</td>\n",
       "      <td>0.557607</td>\n",
       "      <td>0.418133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Category * Attention Level</td>\n",
       "      <td>1.500378</td>\n",
       "      <td>5</td>\n",
       "      <td>110</td>\n",
       "      <td>0.300076</td>\n",
       "      <td>8.182699</td>\n",
       "      <td>1.344844e-06</td>\n",
       "      <td>6.410325e-05</td>\n",
       "      <td>0.271106</td>\n",
       "      <td>0.644188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Source         SS  ddof1  ddof2        MS          F  \\\n",
       "0                    Category   3.457534      1     22  3.457534  10.892946   \n",
       "1             Attention Level  13.437214      5    110  2.687443  27.729559   \n",
       "2  Category * Attention Level   1.500378      5    110  0.300076   8.182699   \n",
       "\n",
       "          p-unc     p-GG-corr       np2       eps  \n",
       "0  3.258622e-03  3.258622e-03  0.331164  1.000000  \n",
       "1  4.463426e-18  8.250565e-09  0.557607  0.418133  \n",
       "2  1.344844e-06  6.410325e-05  0.271106  0.644188  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variable Attention\n",
    "\n",
    "# groupby subject, attention level, category\n",
    "bot = bvar.groupby(['UniqueID','Attention Level','Category'],as_index=False).mean()\n",
    "\n",
    "# repeated measures anova --> familiarity_rating ~ category * attention_level\n",
    "pingouin.rm_anova(dv='Familiarity Rating', within=['Category','Attention Level'], subject='UniqueID', \n",
    "                  data=bot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow up t-test (scene / face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Category</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>Paired</th>\n",
       "      <th>Parametric</th>\n",
       "      <th>T</th>\n",
       "      <th>dof</th>\n",
       "      <th>Tail</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>BF10</th>\n",
       "      <th>hedges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Category</td>\n",
       "      <td>-</td>\n",
       "      <td>Face</td>\n",
       "      <td>Place</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-3.279143</td>\n",
       "      <td>22.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>12.177</td>\n",
       "      <td>-0.649105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Contrast Category     A      B Paired  Parametric         T   dof  \\\n",
       "0  Category        -  Face  Place   True        True -3.279143  22.0   \n",
       "\n",
       "        Tail     p-unc    BF10    hedges  \n",
       "0  two-sided  0.003427  12.177 -0.649105  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pingouin.pairwise_ttests(dv='Familiarity Rating', within=['Category','Attention Level'], subject='UniqueID', \n",
    "                         data=bot).head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novel images, Variable --> Trending towards sig diff between categories (not attention level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contrast</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>Paired</th>\n",
       "      <th>Parametric</th>\n",
       "      <th>T</th>\n",
       "      <th>dof</th>\n",
       "      <th>Tail</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>BF10</th>\n",
       "      <th>hedges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Category</td>\n",
       "      <td>Face</td>\n",
       "      <td>Place</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.239876</td>\n",
       "      <td>22.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.228084</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.222927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Contrast     A      B  Paired  Parametric         T   dof       Tail  \\\n",
       "0  Category  Face  Place    True        True -1.239876  22.0  two-sided   \n",
       "\n",
       "      p-unc   BF10    hedges  \n",
       "0  0.228084  0.431 -0.222927  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pingouin.pairwise_ttests(dv='Familiarity Rating', within=['Category'], subject='UniqueID', \n",
    "                         data=bot[(bot['Attention Level'].isin(['Novel_Cued_Cat','Novel_Uncued_Cat']))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All images, Sustained --> significant effect of Category, Attention Level, and interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sustained Attention\n",
    "\n",
    "# # groupby subject, attention level, category\n",
    "# bot = bsus.groupby(['UniqueID','Attention Level','Category'],as_index=False).mean()\n",
    "\n",
    "# # repeated measures anova --> familiarity_rating ~ category * attention_level\n",
    "# pingouin.rm_anova(dv='Familiarity Rating', within=['Category','Attention Level'], subject='UniqueID', \n",
    "#                   data=bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts = pingouin.pairwise_ttests(dv='Familiarity Rating', within=['Category','Attention Level'], subject='UniqueID',data=bot)\n",
    "# ts[ts['p-unc']<.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novel images, Sustained --> Significant diff for attention level, and interaction, but not category alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>SS</th>\n",
       "      <th>ddof1</th>\n",
       "      <th>ddof2</th>\n",
       "      <th>MS</th>\n",
       "      <th>F</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>p-GG-corr</th>\n",
       "      <th>np2</th>\n",
       "      <th>eps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Category</td>\n",
       "      <td>0.194688</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.194688</td>\n",
       "      <td>1.832825</td>\n",
       "      <td>0.189540</td>\n",
       "      <td>0.189540</td>\n",
       "      <td>0.076903</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attention Level</td>\n",
       "      <td>0.007341</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.007341</td>\n",
       "      <td>0.369653</td>\n",
       "      <td>0.549419</td>\n",
       "      <td>0.549419</td>\n",
       "      <td>0.016525</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Category * Attention Level</td>\n",
       "      <td>0.003901</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.003901</td>\n",
       "      <td>0.240182</td>\n",
       "      <td>0.628927</td>\n",
       "      <td>0.628927</td>\n",
       "      <td>0.010799</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Source        SS  ddof1  ddof2        MS         F  \\\n",
       "0                    Category  0.194688      1     22  0.194688  1.832825   \n",
       "1             Attention Level  0.007341      1     22  0.007341  0.369653   \n",
       "2  Category * Attention Level  0.003901      1     22  0.003901  0.240182   \n",
       "\n",
       "      p-unc  p-GG-corr       np2  eps  \n",
       "0  0.189540   0.189540  0.076903  1.0  \n",
       "1  0.549419   0.549419  0.016525  1.0  \n",
       "2  0.628927   0.628927  0.010799  1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pingouin.rm_anova(dv='Familiarity Rating', within=['Category','Attention Level'], subject='UniqueID', \n",
    "                         data=bot[(bot['Attention Level'].isin(['Novel_Cued_Cat','Novel_Uncued_Cat']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Category</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>Paired</th>\n",
       "      <th>Parametric</th>\n",
       "      <th>T</th>\n",
       "      <th>dof</th>\n",
       "      <th>Tail</th>\n",
       "      <th>p-unc</th>\n",
       "      <th>BF10</th>\n",
       "      <th>hedges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Category</td>\n",
       "      <td>-</td>\n",
       "      <td>Face</td>\n",
       "      <td>Place</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.239876</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.228084</td>\n",
       "      <td>0.431</td>\n",
       "      <td>-0.222927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attention Level</td>\n",
       "      <td>-</td>\n",
       "      <td>Novel_Cued_Cat</td>\n",
       "      <td>Novel_Uncued_Cat</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.776296</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.445841</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.064994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Category * Attention Level</td>\n",
       "      <td>Face</td>\n",
       "      <td>Novel_Cued_Cat</td>\n",
       "      <td>Novel_Uncued_Cat</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.133293</td>\n",
       "      <td>42.873231</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.894585</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-0.038964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Category * Attention Level</td>\n",
       "      <td>Place</td>\n",
       "      <td>Novel_Cued_Cat</td>\n",
       "      <td>Novel_Uncued_Cat</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.218306</td>\n",
       "      <td>42.996049</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.828223</td>\n",
       "      <td>0.301</td>\n",
       "      <td>-0.063908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Contrast Category               A                 B  \\\n",
       "0                    Category        -            Face             Place   \n",
       "1             Attention Level        -  Novel_Cued_Cat  Novel_Uncued_Cat   \n",
       "2  Category * Attention Level     Face  Novel_Cued_Cat  Novel_Uncued_Cat   \n",
       "3  Category * Attention Level    Place  Novel_Cued_Cat  Novel_Uncued_Cat   \n",
       "\n",
       "  Paired  Parametric         T        dof       Tail     p-unc   BF10  \\\n",
       "0   True        True -1.239876  22.000000  two-sided  0.228084  0.431   \n",
       "1   True        True -0.776296  22.000000  two-sided  0.445841  0.287   \n",
       "2   True        True -0.133293  42.873231  two-sided  0.894585  0.297   \n",
       "3   True        True -0.218306  42.996049  two-sided  0.828223  0.301   \n",
       "\n",
       "     hedges  \n",
       "0 -0.222927  \n",
       "1 -0.064994  \n",
       "2 -0.038964  \n",
       "3 -0.063908  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pingouin.pairwise_ttests(dv='Familiarity Rating', within=['Category','Attention Level'], subject='UniqueID', \n",
    "                         data=bot[(bot['Attention Level'].isin(['Novel_Cued_Cat','Novel_Uncued_Cat']))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Behavioral recap\n",
    "\n",
    "In both experiments, category, attention level, and interaction all influence familiarity.\n",
    "\n",
    "#### Within novel images:\n",
    "\n",
    "<b>variable:</b> only category has an influence.\n",
    "\n",
    "<b>sustained:</b> only attention level and interaction have an influence?\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pupil data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_nov['Experiment'] = np.nan\n",
    "d_nov.loc[d_nov['UniqueID']<=29, 'Experiment'] = 'Sustained'\n",
    "d_nov.loc[d_nov['UniqueID']>=30, 'Experiment'] = 'Variable'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing function\n",
    "\n",
    "Link image info from presentation and memory trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_p_level(df):\n",
    "    '''\n",
    "    input: df containing pres and mem from single run\n",
    "    output: df of mem images w/ corresponding pres run and pres trial info\n",
    "    '''\n",
    "\n",
    "    df['p_run'] = np.nan; df['p_trial'] = np.nan\n",
    "    \n",
    "    # loop over the memory trials in this run\n",
    "    for index,row in df[df['Trial Type']=='Memory'].iterrows():\n",
    "\n",
    "        # obtain the image presented in the memory run\n",
    "        mem_image = row['Memory Image']\n",
    "\n",
    "        # look in the columns for previously presented composites\n",
    "        for composite in ['Cued Composite', 'Uncued Composite']:\n",
    "\n",
    "            # if one of the previously seen composites contains the memory image file name (minus the last 4 chars: '.jpg')\n",
    "            if df[df[composite].str.contains(mem_image[:-4], na=False)].shape[0]!=0:\n",
    "                \n",
    "                # pull run info \n",
    "                df['p_run'][index]  = df[df[composite].str.contains(mem_image[:-4], na=False)]['Run'].item()\n",
    "                \n",
    "                # pull trial info\n",
    "                df['p_trial'][index] = df[df[composite].str.contains(mem_image[:-4], na=False)]['Trial'].item()\n",
    "                   \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_list = []\n",
    "\n",
    "# for each participant (behavioral)\n",
    "for s in b['UniqueID'].unique():\n",
    "    \n",
    "    # make df where their mem trials indexed by pres trials...\n",
    "    big_list.append(run_p_level(b[b['UniqueID']==s]))\n",
    "    \n",
    "labeled = pd.concat(big_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled[~labeled['p_run'].isna()]['p_run'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# labeled[(~labeled['p_run'].isna())&(~labeled['Familiarity Rating'].isna())][['p_run','p_trial','UniqueID','Attention Level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d_nov['Familiarity Rating'],d_nov['Attention Level'] = np.nan, np.nan\n",
    "\n",
    "# for each mem row of prev seen that got a rating...\n",
    "for index,row in labeled[(labeled['Familiarity Rating'].isin([1,2,3,4]))&(labeled['p_run'].isin([0,1,2,3,4,5,6,7]))].iterrows():\n",
    "\n",
    "    p_run   = row['p_run']\n",
    "    p_trial = row['p_trial']\n",
    "    \n",
    "    d_nov.loc[(d_nov['Run']==p_run)&(d_nov['Trial']==p_trial),'Familiarity Rating'] = row['Familiarity Rating']\n",
    "    d_nov.loc[(d_nov['Run']==p_run)&(d_nov['Trial']==p_trial),'Attention Level']    = row['Attention Level']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_nov['Familiarity Rating'],d_nov['Attention Level'] = np.nan, np.nan\n",
    "\n",
    "# for each mem row of prev seen that got a rating...\n",
    "for index,row in labeled[(~labeled['p_run'].isna())&(~labeled['Familiarity Rating'].isna())&(labeled['Trial Type']=='Memory')].iterrows():\n",
    "\n",
    "    p_run   = row['p_run']\n",
    "    p_trial = row['p_trial']\n",
    "    run     = row['Run']\n",
    "    trial   = row['Trial']\n",
    "    \n",
    "    d_nov.loc[(d_nov['Run']==run)&(d_nov['Trial']==trial),'Familiarity Rating'] = row['Familiarity Rating']\n",
    "    d_nov.loc[(d_nov['Run']==run)&(d_nov['Trial']==trial),'Attention Level']    = row['Attention Level']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by experiment, participant, timepoint\n",
    "attn_group = d_nov[d_nov['Attention Level'].isin(['Full','Category',\n",
    "                                                  'Side','None'])].groupby(['Experiment',\n",
    "                                                                            'UniqueID','Time'], as_index=False).mean()\n",
    "missing_subs = []\n",
    "\n",
    "# mean prev seen figure\n",
    "plt.figure(figsize=(3, 4));\n",
    "sb.lineplot(x='Time', y='Interp', data=attn_group, linewidth = 2, palette=\"RdBu\")\n",
    "plt.savefig('Average_Pres_All.pdf')\n",
    "\n",
    "# sub_mean has average pupil response at each timepoint across all participants\n",
    "sub_mean = attn_group.groupby(['Time'],as_index=False).mean()\n",
    "\n",
    "# pup_mean is the average pupil dilation value across all timepoints \n",
    "pup_mean = sub_mean['Interp'].mean()\n",
    "\n",
    "# label each time in the mean timecourse as above or below pup_mean\n",
    "sub_mean['mean_divide'] = np.nan\n",
    "sub_mean.loc[sub_mean['Interp']<pup_mean,  'mean_divide'] = 0\n",
    "sub_mean.loc[sub_mean['Interp']>pup_mean,  'mean_divide'] = 2\n",
    "sub_mean.loc[sub_mean['Interp']==pup_mean, 'mean_divide'] = 1\n",
    "mean_div_list = list(sub_mean['mean_divide'])\n",
    "\n",
    "# for each labeled timepoint\n",
    "for idx,x in enumerate(mean_div_list):\n",
    "    \n",
    "    # if that point's label does not match its neighbors' labels\n",
    "    if x != mean_div_list[idx-1] and x!= mean_div_list[idx+1]:\n",
    "        \n",
    "        # switch it to match its neighbors\n",
    "        if mean_div_list[idx-1] == mean_div_list[idx+1]:\n",
    "            mean_div_list[idx] = mean_div_list[idx+1]\n",
    "            print('fixed one at index:'+str(idx))\n",
    "        else:\n",
    "            print(\"issue!\")\n",
    "            \n",
    "# add corrected labels to sub_mean df\n",
    "sub_mean['mean_divide'] = mean_div_list\n",
    "\n",
    "# MAKE BINS\n",
    "# start first bin with timepoint 0\n",
    "bins=[0]\n",
    "\n",
    "# for each labeled timepoint\n",
    "for idx,row in sub_mean.iterrows():\n",
    "    if idx != 0:\n",
    "        \n",
    "        # save the timepoints where each block of labels changes\n",
    "        if row['mean_divide']!=sub_mean['mean_divide'][idx-1]:\n",
    "            plt.vlines(row['Time'], -2, 2)\n",
    "            bins.append(sub_mean['Time'][idx-1])\n",
    "            bins.append(row['Time'])\n",
    "            \n",
    "# end last bin with last timepoint\n",
    "bins.append(3)\n",
    "\n",
    "# make df of time bin boundaries and save to csv\n",
    "key_name = 'Both'; filename = 'Both_PrevSeen_Bins.csv'\n",
    "bin_df = pd.DataFrame({key_name:bins})\n",
    "bin_df.to_csv(filename)\n",
    "\n",
    "# plot pup_mean as horizontal line\n",
    "plt.hlines(pup_mean, 0, 3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# make plot\n",
    "plt.xlim((0 , 3)); plt.ylim((-2, 2.25)); plt.tick_params(labelsize=20)\n",
    "plt.xlabel(\"Time from image onset (s)\", size = 20); plt.ylabel(\"Pupil diameter (z-score)\", size = 20)\n",
    "plt.title('Both_'+'MEAN'+'_'+'pres')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "fig_name = 'NEW_'+'ALL'+'_'+'MEAN'+'_'+'PREV_SEEN_PRES_CHUNK'+'.pdf'\n",
    "\n",
    "plt.savefig(fig_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Plots with Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binnies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_nov['Familiarity'] = np.nan\n",
    "d_nov.loc[(d_nov['Familiarity Rating']==1) | (d_nov['Familiarity Rating']==2), 'Familiarity'] = 'Unfamiliar'\n",
    "d_nov.loc[(d_nov['Familiarity Rating']==3) | (d_nov['Familiarity Rating']==4), 'Familiarity'] = 'Familiar'\n",
    "attn_group = d_nov.groupby(['Experiment','UniqueID','Familiarity','Time','Attention Level'], as_index=False).mean()\n",
    "\n",
    "# for each experiment\n",
    "# for e in ['Sustained','Variable']:\n",
    "    \n",
    "binnies =  pd.read_csv('Both_PrevSeen_Bins.csv')\n",
    "binnies = list(binnies['Both'])\n",
    "\n",
    "# for each attention level\n",
    "for c in attn_group['Attention Level'].unique():\n",
    "\n",
    "    # for each chunk\n",
    "    chunk_1 = attn_group[(attn_group['Attention Level']==c)&(attn_group['Time']>=binnies[0])&(attn_group['Time']<=binnies[1])]\n",
    "    chunk_2 = attn_group[(attn_group['Attention Level']==c)&(attn_group['Time']>=binnies[2])&(attn_group['Time']<=binnies[3])]\n",
    "    chunk_3 = attn_group[(attn_group['Attention Level']==c)&(attn_group['Time']>=binnies[4])&(attn_group['Time']<=binnies[5])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "\n",
    "# chunk_1 = chunk_1.groupby(['UniqueID','Familiarity'], as_index=False).mean()\n",
    "# scipy.stats.ttest_ind(chunk_1[chunk_1['Familiarity']=='Familiar']['Interp'],chunk_1[chunk_1['Familiarity']=='Unfamiliar']['Interp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add labels combining ratings 1-2 and 3-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_nov['Familiarity'] = np.nan\n",
    "d_nov.loc[(d_nov['Familiarity Rating']==1) | (d_nov['Familiarity Rating']==2), 'Familiarity'] = 'Unfamiliar'\n",
    "d_nov.loc[(d_nov['Familiarity Rating']==3) | (d_nov['Familiarity Rating']==4), 'Familiarity'] = 'Familiar'\n",
    "attn_group = d_nov.groupby(['Experiment','UniqueID','Familiarity','Time','Attention Level'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "binnies =  pd.read_csv('Both_PrevSeen_Bins.csv')\n",
    "binnies = list(binnies['Both'])\n",
    "\n",
    "# for each attention level\n",
    "for c in attn_group['Attention Level'].unique():\n",
    "\n",
    "        # for each chunk\n",
    "        chunk_1 = attn_group[(attn_group['Attention Level']==c)&(attn_group['Time']>=binnies[0])&\n",
    "                             (attn_group['Time']<=binnies[1])]\n",
    "        chunk_1 = chunk_1.groupby(['UniqueID','Familiarity'], as_index=False).mean()\n",
    "        one = scipy.stats.ttest_ind(chunk_1[chunk_1['Familiarity']=='Familiar']['Interp'],\n",
    "                                    chunk_1[chunk_1['Familiarity']=='Unfamiliar']['Interp'])\n",
    "\n",
    "        chunk_2 = attn_group[(attn_group['Attention Level']==c)&\n",
    "                             (attn_group['Time']>=binnies[2])&(attn_group['Time']<=binnies[3])]\n",
    "        chunk_2 = chunk_2.groupby(['UniqueID','Familiarity'], as_index=False).mean()\n",
    "        two = scipy.stats.ttest_ind(chunk_2[chunk_2['Familiarity']=='Familiar']['Interp'],\n",
    "                                    chunk_2[chunk_2['Familiarity']=='Unfamiliar']['Interp'])\n",
    "\n",
    "        chunk_3 = attn_group[(attn_group['Attention Level']==c)\n",
    "                             &(attn_group['Time']>=binnies[4])&(attn_group['Time']<=binnies[5])]\n",
    "        chunk_3 = chunk_3.groupby(['UniqueID','Familiarity'], as_index=False).mean()\n",
    "        three = scipy.stats.ttest_ind(chunk_3[chunk_3['Familiarity']=='Familiar']['Interp'],\n",
    "                                      chunk_3[chunk_3['Familiarity']=='Unfamiliar']['Interp'])\n",
    "\n",
    "        \n",
    "        \n",
    "        plt.figure(figsize=(3.25, 4)); #print(e);print(c);\n",
    "\n",
    "        # palette = sns.color_palette(\"ch:s=-.2,r=.6\", as_cmap=True)\n",
    "\n",
    "        sb.lineplot(x='Time', y='Interp', hue='Familiarity', \n",
    "                    data=attn_group[attn_group['Attention Level']==c], \n",
    "                    linewidth = 2, palette='PuOr_r')\n",
    "\n",
    "        plt.ylim(-2, 2.25); plt.xlim(0,3); plt.tight_layout()\n",
    "\n",
    "        plt.savefig('all_'+c+'_presentation.pdf')\n",
    "        plt.show()\n",
    "        \n",
    "        # pairwise t-tests\n",
    "        # print result\n",
    "        for n in [one, two, three]:\n",
    "            if n.pvalue<=.06:\n",
    "                print(c+' chunk ' + str(n)+': '); print(n); print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
