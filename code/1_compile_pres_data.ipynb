{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; import os; from analysis_helpers import *; import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Compile\n",
    "This cell takes a long time to run. \n",
    "\n",
    "It will print each participant number to give a sense of the progress (finishing at paticipant 112)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pres_gaze_from_df(behavioral_df, eye_df):\n",
    "    '''\n",
    "    input: participant's behavioral df\n",
    "           participant's eye track df\n",
    "    output: single df of gaze data for this participant, when pres images on screen\n",
    "    '''\n",
    "    # empty lists for pres_gaze and no_gaze (runs w/ very few recorded datapoints)\n",
    "    pres_gaze = []\n",
    "    no_gaze = []\n",
    "\n",
    "    # for each presentation row in the behavioral df\n",
    "    for idx,x in behavioral_df[behavioral_df['Trial Type']=='Presentation'].iterrows():\n",
    "\n",
    "        # select times when visual stimuli appear & disappear\n",
    "        start,end = x['Stimulus Onset'],x['Stimulus End']\n",
    "\n",
    "        # select gaze data from interval stim was on screen\n",
    "        chunk = eye_df.loc[(eye_df['timestamp']>=start) & (eye_df['timestamp']<=end)]\n",
    "\n",
    "        # add trial and run numbers\n",
    "        chunk['Trial'] = np.nan\n",
    "        chunk['Run']   = np.nan\n",
    "        chunk['Trial'] = x['Trial']\n",
    "        chunk['Run']   = x['Run']\n",
    "\n",
    "        # add start times to separate row\n",
    "        chunk['Behavior_Image_Start'] = start\n",
    "\n",
    "        # # if there are fewer than five gazepoints, also add this chunk to no_gaze\n",
    "        # if chunk.shape[0] <5:\n",
    "        #     no_gaze.append(chunk)\n",
    "\n",
    "        # append the gaze data for each trial to a list\n",
    "        pres_gaze.append(chunk)\n",
    "\n",
    "    # concat data from all runs and trials\n",
    "    pres_gaze = pd.concat(pres_gaze)\n",
    "    # no_gaze = pd.concat(no_gaze)\n",
    "\n",
    "    return(pres_gaze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compile data from all exps\n",
    "\n",
    "all_data = []; all_gaze = []\n",
    "\n",
    "data_dirs = ['../data/sustained_attention_experiment/','../data/variable_attention_experiment/'] \n",
    "filenames = [x+'aggregate.csv' for x in data_dirs]\n",
    "\n",
    "sub_count = 0\n",
    "\n",
    "# for each experiment (sustained and variable)\n",
    "for data,file in zip(data_dirs, filenames):\n",
    "    \n",
    "    # empty subject list\n",
    "    sub_list = []\n",
    "    \n",
    "    # for each subject in this directory\n",
    "    for sub_dir in os.listdir(data):\n",
    "        \n",
    "        if sub_dir != '.DS_Store' and sub_dir != 'README.md': #0_2020_Feb_07\n",
    "            \n",
    "            # add attention labels to memory stim \n",
    "            subject = add_level(sum_pd(data + '/' + sub_dir))\n",
    "\n",
    "            # organize ON and OFF stim times \n",
    "            subject_log = list_logs(data + '/' + sub_dir + '/')\n",
    "            subject_log['Subject'] = pd.to_numeric(subject_log['Subject'])\n",
    "            subject_log = subject_log.sort_values(by=['Subject','Run','TIME'])\n",
    "            subject = subject.sort_values(by=['Subject','Run'])\n",
    "\n",
    "            # extract desired stim ON and OFF times from log files\n",
    "            composite_onsets  = subject_log[subject_log[0].str.contains('COMPOSITES ON')]\n",
    "            composite_offsets = subject_log[subject_log[0].str.contains('COMPOSITES OFF')]\n",
    "            memory_onsets  = list(subject_log[ (subject_log[0].str.contains('MEMORY ON')) & (subject_log[0].str.contains('FLIP')) ]['TIME'])\n",
    "            memory_offsets = list(subject_log[ (subject_log[0].str.contains('MEMORY OFF')) & (subject_log[0].str.contains('FLIP')) ]['TIME'])\n",
    "\n",
    "            # add ON and OFF stim times from log files to df\n",
    "            subject.loc[subject['Trial Type']=='Presentation', 'Stimulus Onset'] = list(composite_onsets['TIME'])\n",
    "            subject.loc[subject['Trial Type']=='Presentation', 'Stimulus End'  ] = list(composite_offsets['TIME'])\n",
    "            subject.loc[subject['Trial Type']=='Presentation','Attention Response Time (s)'] = subject[subject['Trial Type']=='Presentation']['Attention Response Time (s)'] - subject[subject['Trial Type']=='Presentation']['Stimulus End']\n",
    "            subject.loc[subject['Trial Type']=='Memory', 'Stimulus Onset'] = memory_onsets\n",
    "            subject.loc[subject['Trial Type']=='Memory', 'Stimulus End'  ] = memory_offsets\n",
    "\n",
    "            # Pull attention RT's from log file\n",
    "\n",
    "            # find every probe display, and the next event after each probe display\n",
    "            probe_time_indices = subject_log[(subject_log[0].str.contains('ATTN'))].index\n",
    "            key_press_indices  = [x+1 for x in list(probe_time_indices)]\n",
    "\n",
    "            # if next event isn't keypress 1 or keypress 3, go until you find the first keypress 1 or 3\n",
    "            for idx,x in enumerate(key_press_indices):\n",
    "                while 'Keypress: 1' not in str(subject_log.loc[x][0]) and 'Keypress: 3' not in str(subject_log.loc[x][0]):\n",
    "                    x+=1\n",
    "                key_press_indices[idx]=x\n",
    "\n",
    "            ##############################################################################\n",
    "\n",
    "            attn_rt = {}\n",
    "            attn_rt['probe_start'] = [] #list(subject_log.loc[probe_time_indices]['TIME'])\n",
    "            attn_rt['key press' ] = [] #list(subject_log.loc[key_press_indices ]['TIME'])\n",
    "            a = []\n",
    "            b=[]\n",
    "\n",
    "            for r in subject_log['Run'].unique():\n",
    "\n",
    "                run_log = subject_log[subject_log['Run']==r]\n",
    "\n",
    "               # find every probe display, and the next event after each probe display\n",
    "                probe_time_indices = run_log[(run_log[0].str.contains('ATTN'))].index\n",
    "                key_press_indices  = [x+1 for x in list(probe_time_indices)]\n",
    "\n",
    "               # if next event isn't keypress 1 or keypress 3, go until you find the first keypress 1 or 3\n",
    "                for idx,x in enumerate(key_press_indices):\n",
    "                    while 'Keypress: 1' not in str(run_log.loc[x][0]) and 'Keypress: 3' not in str(run_log.loc[x][0]):\n",
    "                        x+=1\n",
    "                    key_press_indices[idx]=x\n",
    "                   # then stop and collect the time of the button press\n",
    "\n",
    "                a.extend(list(run_log.loc[probe_time_indices]['TIME']))\n",
    "                b.extend(list(run_log.loc[key_press_indices ]['TIME']))\n",
    "\n",
    "            attn_rt['probe_start'] = a\n",
    "            attn_rt['key press' ]  = b\n",
    "            attn_df = pd.DataFrame(attn_rt)\n",
    "            log_file_rt = attn_df['key press'].astype('float64')-attn_df['probe_start'].astype('float64')\n",
    "            subject.loc[subject['Trial Type']=='Presentation','Attention Response Time (s)'] = list(log_file_rt)\n",
    "            subject.loc[subject['Trial Type']=='Presentation','Attention Reaction Time (s)'] = list(log_file_rt)\n",
    "\n",
    "            ##############################################################################\n",
    "\n",
    "            # Convert all times to be eyetribe compatible\n",
    "            for r in subject['Run'].unique():\n",
    "                time = float(subject_log[subject_log['Run']==r].loc[subject_log[subject_log['Run']==r][0].str.contains('urrent time')]['TIME'])\n",
    "                curr_string = subject_log[subject_log['Run']==r].loc[subject_log[subject_log['Run']==r][0].str.contains('urrent time')][0].str.split(' ')\n",
    "                curr_time = float(list(curr_string)[0][-1])\n",
    "                diff = curr_time - time\n",
    "\n",
    "                # convert times for each run\n",
    "                subject.loc[subject['Run']==r, 'Stimulus Onset'] = subject.loc[subject['Run']==r, 'Stimulus Onset'] + diff\n",
    "                subject.loc[subject['Run']==r, 'Stimulus End']   = subject.loc[subject['Run']==r, 'Stimulus End'] + diff\n",
    "\n",
    "            subject = subject.rename(columns={'Attention Response Time (s)': 'Attention Reaction Time (s)'})\n",
    "\n",
    "            # add trial numbers to behavioral data\n",
    "            subject['Trial'] = np.nan\n",
    "            subject.loc[subject['Trial Type']=='Memory','Trial']       = list(range(0,40))*8\n",
    "            subject.loc[subject['Trial Type']=='Presentation','Trial'] = list(range(0,10))*8\n",
    "                \n",
    "            # Gaze data \n",
    "            gaze = eye_initial(data + '/' + sub_dir + '/eye_data/')\n",
    "        \n",
    "            gaze['Subject']  = sub_dir.split('_')[0]\n",
    "            gaze['UniqueID'] = sub_count\n",
    "            gaze['Experiment'] = data[2:10]\n",
    "            \n",
    "            pres_gaze = pres_gaze_from_df(subject, gaze)\n",
    "            \n",
    "            # Give every subj unique ID, label group & experiment\n",
    "            subject['UniqueID'] = sub_count\n",
    "            subject['Experiment'] = data[2:10]\n",
    "            \n",
    "            sub_count += 1\n",
    "            sub_list.append(subject)\n",
    "            subject.to_csv(data + '/' + sub_dir + '/subject_b_data.csv')\n",
    "            pres_gaze.to_csv(data + '/' + sub_dir + '/subject_pres_gaze_data.csv')\n",
    "            \n",
    "#     exp_raw = pd.concat(sub_list)\n",
    "#     exp_raw.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34_2019_Oct_13\n",
      "40_2019_Oct_17\n",
      "7_2019_Oct_13\n",
      "13_2019_Oct_14\n",
      "39_2019_Oct_17\n",
      "16_2019_Oct_08\n",
      "2_2019_Oct_06\n",
      "8_2019_Oct_13\n",
      "32_2019_Oct_15\n",
      "15_2019_Oct_14\n",
      "5_2019_Oct_17\n",
      "1_2019_Oct_13\n",
      "10_2019_Oct_14\n",
      "19_2019_Oct_15\n",
      "4_2019_Oct_13\n",
      "28_2019_Oct_09\n",
      "7_2019_Oct_13_b\n",
      "14_2019_Oct_07\n",
      "3_2019_Oct_13\n",
      "18_2019_Oct_08\n",
      "38_2019_Oct_17\n",
      "35_2019_Oct_13\n",
      "11_2019_Oct_14_b\n",
      "20_2019_Oct_08\n",
      "36_2019_Oct_13\n",
      "5_2019_Oct_13\n",
      "11_2019_Oct_14\n",
      "0_2019_Oct_13\n",
      "25_2019_Oct_08\n",
      "9_2019_Oct_14\n",
      "56_2020_Feb_21\n",
      "17_2019_Nov_18\n",
      "12_2019_Nov_17\n",
      "20_2019_Nov_19\n",
      "30_2020_Jan_13\n",
      "25_2020_Jan_24\n",
      "11_2019_Nov_17\n",
      "18_2019_Nov_19\n",
      "9_2019_Nov_16\n",
      "29_2020_Jan_13\n",
      "14_2019_Nov_17\n",
      "21_2019_Nov_19\n",
      "27_2020_Jan_15\n",
      "6_2019_Nov_15\n",
      "16_2019_Nov_18\n",
      "26_2020_Jan_16\n",
      "28_2020_Jan_13\n",
      "8_2019_Nov_16\n",
      "15_2019_Nov_18\n",
      "5_2019_Nov_15\n",
      "19_2019_Nov_19\n",
      "10_2019_Nov_16\n",
      "0_2020_Feb_07\n"
     ]
    }
   ],
   "source": [
    "# compile gaze df's from each subject\n",
    "paths    = ['../data/sustained_attention_experiment/', '../data/variable_attention_experiment/']\n",
    "all_subs = []; all_gazes = []\n",
    "\n",
    "for exp in paths:\n",
    "    \n",
    "    subjects = os.listdir(exp)\n",
    "\n",
    "    for s in subjects:\n",
    "        if s != '.DS_Store' and s != 'aggregate.csv':\n",
    "            \n",
    "            print(s)\n",
    "\n",
    "            subject  = pd.read_csv(exp+s+'/subject_b_data.csv')\n",
    "            gaze     = pd.read_csv(exp+s+'/subject_pres_gaze_data.csv')\n",
    "\n",
    "            all_gazes.append(gaze); all_subs.append(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gazes  = pd.concat(all_gazes); all_gazes.to_csv('pres_gaze_b.csv')\n",
    "all_behavs = pd.concat(all_subs);  all_behavs.to_csv('behav_b.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
